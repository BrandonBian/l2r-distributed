apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: l2r-dcollect-workers
  labels:
    tier: l2r-dcollect-workers
spec:
  # 2 to start, then for phortx 30-40 is the upper bound probably
  replicas: 1
  selector:
    matchLabels:
      tier: l2r-dcollect-workers
  template:
    metadata:
      labels:
        tier: l2r-dcollect-workers
    spec:
      # nodeSelector:
      #   # we don't specify the cluster, maybe it's ok to just delete the phortx stuff?
      #   # 1-3
      #   nodetype: phortx2
      containers:
      - name: l2r-dcollect-workers
        tty: true
        stdin: true
        resources: # Maybe a good idea to have the learner on its own gpu, specify like below
            limits:
                nvidia.com/gpu: 1
        env:
        # This is the tricky bit, We're not claiming the pods, we might end up sharing it
        # not-yet done bit: multiple worker sets for each gpu group in the hardware
        #### Change GPUs if you want more replica sets
        # "{{GPU_ID}}" 
          - name: NVIDIA_VISIBLE_DEVICES 
            value: "2" # 0-7??
          - name: CUDA_VISIBLE_DEVICES
            value: "0" # has to match the above
        image: docker.pdl.cmu.edu/l2r2022:latest
        command: # gonna have to make this smarter
          - /bin/bash
          - -c
          - apt-get update && 
            apt-get install xvfb swig -y && 
            pip3 install tianshou gym strictyaml line_profiler &&
            pip3 install git+https://github.com/learn-to-race/l2r.git@aicrowd-environment tianshou gym strictyaml wandb tensorboardX jsonpickle && 
            git clone https://github.com/BrandonBian/l2r-distributed && 
            cd l2r-distributed &&
            pip3 install -r setup/devtools_reqs.txt &&
            pip3 install wandb tensorboardX jsonpickle && 
            pip3 install gym[box2d] protobuf==3.20.* &&
            sudo -u ubuntu xvfb-run --server-num 1 /workspace/LinuxNoEditor/ArrivalSim.sh -openGL &
            sleep infinity 
            # pwd && 
            # cd l2r && 
            # python3 distributedworker.py

---
apiVersion: v1
kind: Pod
metadata:
  name: l2r-dcollect-learner
  labels:
    app.kubernetes.io/name: proxy
spec:
  hostname: learner-1
  nodeSelector:
    nodetype: phortx
  containers:
    - name: l2r-dcollect-learner
      tty: true
      stdin: true
      resources: # Maybe a good idea to have the learner on its own gpu, specify like below
        limits:
          nvidia.com/gpu: 1
      image: docker.pdl.cmu.edu/l2r2022:latest # Slightly different image or files or git repo
      command: # gonna have to make this smarter
        - /bin/bash
        - -c
        - pip3 install git+https://github.com/learn-to-race/l2r.git@aicrowd-environment tianshou gym strictyaml wandb tensorboardX jsonpickle && 
          git clone https://github.com/BrandonBian/l2r-distributed && 
          cd l2r-distributed && 
          sleep infinity 
          # python3 distributedserver.py 173e38ab5f2f2d96c260f57c989b4d068b64fb8a

      ports:
      - name: l2r-dcollect
        containerPort: 4444
--- 
apiVersion: v1
kind: Service
metadata:
  name: l2r-dcollect-learner
spec:
  selector:
    app.kubernetes.io/name: proxy
  ports:
  - name: l2r-dcollect
    protocol: TCP
    port: 4444
    targetPort: l2r-dcollect
